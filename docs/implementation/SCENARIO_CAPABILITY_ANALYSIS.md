# E2E Scenario Capability Analysis

**Date**: 2025-10-16
**Purpose**: Analyze each of the 18 scenarios against current codebase implementation

---

## Executive Summary

**Current Implementation Status**: Phase 1A-1D + Partial Phase 2

**Overall Scenario Coverage**:
- ‚úÖ **Fully Capable** (4/18 = 22%): Scenarios 1, 4, 5, 9
- üü° **Partially Capable** (12/18 = 67%): Scenarios 2, 3, 6, 7, 8, 10, 11, 12, 13, 14, 15, 17
- ‚ùå **Missing Core Features** (2/18 = 11%): Scenarios 16, 18

**Key Strengths**:
- Complete 6-layer memory architecture (all tables exist)
- Entity resolution pipeline (5-stage hybrid)
- Semantic extraction with conflict detection
- Domain augmentation with database queries
- Memory scoring with multi-signal retrieval
- LLM reply generation with context

**Key Gaps**:
- Procedural memory extraction (LLM-based policy extraction)
- Active validation prompting (aging memory validation)
- Multi-hop ontology traversal (customer ‚Üí SO ‚Üí WO ‚Üí Invoice)
- Task/work order domain queries (only customers/invoices/SOs implemented)
- Consolidation API endpoints
- Explainability API endpoints
- Disambiguation flow API

---

## Current Implementation Overview

### Database Schema ‚úÖ COMPLETE

All 10 tables from VISION.md implemented in `models.py`:

| Layer | Table | Status | Notes |
|-------|-------|--------|-------|
| 1 | ChatEvent | ‚úÖ Complete | Immutable audit trail |
| 2 | CanonicalEntity | ‚úÖ Complete | Entity storage with external_ref |
| 2 | EntityAlias | ‚úÖ Complete | Global + user-specific aliases |
| 3 | EpisodicMemory | ‚úÖ Complete | Events with meaning |
| 4 | SemanticMemory | ‚úÖ Complete | Facts with lifecycle (confidence, status) |
| 5 | ProceduralMemory | ‚úÖ Complete | Learned heuristics (trigger patterns) |
| 6 | MemorySummary | ‚úÖ Complete | Cross-session consolidation |
| Support | DomainOntology | ‚úÖ Complete | Relationship semantics |
| Support | MemoryConflict | ‚úÖ Complete | Explicit conflict tracking |
| Support | SystemConfig | ‚úÖ Complete | Heuristic configuration |

**Verdict**: Database schema is production-ready. No additional tables needed.

---

### Service Layer (from `src/domain/services/`)

**Phase 1A - Entity Resolution** ‚úÖ
- `EntityResolutionService`: 5-stage hybrid (exact/alias/fuzzy/LLM/domain-DB)
- `SimpleMentionExtractor`: Mention extraction from text

**Phase 1B - Semantic Extraction** ‚úÖ
- `SemanticExtractionService`: LLM triple extraction
- `MemoryValidationService`: Confidence decay, reinforcement
- `ConflictDetectionService`: Memory vs memory, memory vs DB conflict detection

**Phase 1C - Domain Augmentation** ‚úÖ
- `DomainAugmentationService`: Query domain database (customers, invoices, sales_orders, payments)

**Phase 1D - Memory Scoring & Consolidation** ‚úÖ
- `MultiSignalScorer`: Multi-signal relevance scoring
- `ConsolidationService`: Memory summarization
- `ConsolidationTriggerService`: Trigger-based consolidation
- `ProceduralMemoryService`: Procedural memory management

**Supporting Services** ‚úÖ
- `LLMReplyGenerator`: Natural language reply generation
- `PIIRedactionService`: PII detection/redaction
- `DebugTraceService`: Observability and debugging

**Verdict**: Core service layer is comprehensive. Missing: LLM-based procedural extraction, active validation prompts, multi-hop queries.

---

### API Flow (ProcessChatMessageUseCase)

**Current Pipeline** (from `process_chat_message.py`):

```
1. Store chat message ‚Üí ChatEvent ‚úÖ
2. Resolve entities ‚Üí EntityResolutionService (Phase 1A) ‚úÖ
3. Extract semantics ‚Üí SemanticExtractionService (Phase 1B) ‚úÖ
4. Augment with domain ‚Üí DomainAugmentationService (Phase 1C) ‚úÖ
5. Score memories ‚Üí MultiSignalScorer (Phase 1D) ‚úÖ
6. Generate reply ‚Üí LLMReplyGenerator ‚úÖ
```

**Output** (ProcessChatMessageOutput):
- `event_id`, `session_id`
- `resolved_entities[]` (entity_id, canonical_name, entity_type, confidence, method)
- `semantic_memories[]` (predicate, object_value, confidence)
- `conflict_count`
- `domain_facts[]` (fact_type, entity_id, content, source_table, source_rows)
- `retrieved_memories[]` (memory_id, memory_type, relevance_score, confidence)
- `reply` (LLM-generated natural language response)

**Verdict**: Pipeline is complete for core scenarios. Missing: Procedural memory extraction in pipeline, active validation in pipeline.

---

## Scenario-by-Scenario Analysis

### ‚úÖ Scenario 1: Overdue Invoice with Preference Recall

**ProjectDescription**: "User asks about overdue invoice INV-1009. System retrieves invoice from DB + recalls learned preference 'Gai prefers Friday deliveries'."

**Required Capabilities**:
1. Entity resolution for "INV-1009" and "Gai" ‚úÖ
2. Domain DB query for invoice status ‚úÖ
3. Memory retrieval for delivery preferences ‚úÖ
4. Multi-signal scoring to rank memories ‚úÖ
5. LLM reply combining DB + memory ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService resolves "INV-1009" (invoice) and "Gai" (customer)
- ‚úÖ DomainAugmentationService queries `domain.invoices` and `domain.customers`
- ‚úÖ MultiSignalScorer retrieves semantic memories with high relevance
- ‚úÖ LLMReplyGenerator combines domain_facts + retrieved_memories
- ‚úÖ Reply includes both DB truth (invoice status) + contextual truth (preferences)

**Test Status**: ‚úÖ PASSING (test_scenario_01)

**Verdict**: **FULLY CAPABLE** - All infrastructure in place.

---

### ‚úÖ Scenario 4: NET Terms Learning from Conversation

**ProjectDescription**: "User says 'TC Boiler uses NET15 terms'. System extracts semantic fact and stores."

**Required Capabilities**:
1. Entity resolution for "TC Boiler" ‚úÖ
2. Semantic extraction: `{subject: "TC Boiler", predicate: "payment_terms", object_value: "NET15"}` ‚úÖ
3. Semantic memory storage ‚úÖ
4. Confidence assignment ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService resolves "TC Boiler" to customer entity
- ‚úÖ SemanticExtractionService uses LLM to extract triple
- ‚úÖ SemanticMemory table stores with confidence, predicate_type, provenance
- ‚úÖ Reply acknowledges learning

**Test Status**: ‚úÖ PASSING (test_scenario_04)

**Verdict**: **FULLY CAPABLE** - Semantic extraction works end-to-end.

---

### ‚úÖ Scenario 5: Partial Payments and Balance

**ProjectDescription**: "User asks about invoice INV-1009 with multiple payments. System queries invoice + payments, calculates balance."

**Required Capabilities**:
1. Entity resolution for "INV-1009" ‚úÖ
2. Domain DB joins: `invoices` LEFT JOIN `payments` ‚úÖ
3. Balance calculation (amount - SUM(payments)) ‚úÖ
4. LLM reply with calculated balance ‚úÖ

**Current Implementation**:
- ‚úÖ DomainAugmentationService queries both `domain.invoices` and `domain.payments`
- ‚úÖ EntityInfo includes join logic (invoice_id foreign key)
- ‚úÖ Domain facts include payment amounts
- ‚úÖ LLMReplyGenerator synthesizes balance

**Test Status**: ‚úÖ PASSING (test_scenario_05)

**Verdict**: **FULLY CAPABLE** - Database join logic works.

---

### ‚úÖ Scenario 9: Cold-Start Grounding to DB

**ProjectDescription**: "First query about SO-2002 (no prior memories). System grounds response purely in DB facts."

**Required Capabilities**:
1. Entity resolution for "SO-2002" ‚úÖ
2. Domain DB query for sales_order ‚úÖ
3. No memory retrieval (cold start) ‚úÖ
4. Episodic memory creation ‚úÖ
5. LLM reply from DB facts only ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService resolves SO-2002 (may use domain DB lookup)
- ‚úÖ DomainAugmentationService queries `domain.sales_orders`
- ‚úÖ MultiSignalScorer returns empty (no semantic memories yet)
- ‚úÖ ChatEvent and EpisodicMemory created for this first interaction
- ‚úÖ LLMReplyGenerator uses only domain_facts (no retrieved_memories)

**Test Status**: ‚úÖ PASSING (test_scenario_09)

**Verdict**: **FULLY CAPABLE** - Cold-start path works correctly.

---

### üü° Scenario 2: Work Order Rescheduling

**ProjectDescription**: "User asks to reschedule work order. System checks technician availability + customer scheduling preferences."

**Required Capabilities**:
1. Entity resolution for work order + customer ‚úÖ
2. Domain DB query for `work_orders` ‚ùå
3. Domain DB query for technician availability ‚ùå
4. Memory retrieval for scheduling preferences ‚úÖ
5. LLM reply with rescheduling options ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService can resolve entities
- ‚ùå DomainAugmentationService doesn't query `domain.work_orders` table yet
- ‚ùå No technician table/query support
- ‚úÖ Memory retrieval works if preferences exist
- ‚úÖ LLMReplyGenerator can synthesize response

**Missing**:
```python
# In DomainAugmentationService._get_entity_info()
elif entity_type == "work_order":
    return EntityInfo(
        table="domain.work_orders",
        id_field="wo_id",
        name_field="wo_number",
        join_from="sales_orders",  # work_orders.so_id ‚Üí sales_orders.so_id
        related_tables=["tasks"]
    )
```

**Verdict**: **PARTIAL** - Need to add work_order queries to DomainAugmentationService (2-3 hours work).

---

### üü° Scenario 3: Ambiguous Entity Disambiguation

**ProjectDescription**: "User says 'Acme'. Two customers match: 'Acme Corp' and 'Acme Industries'. System asks for clarification."

**Required Capabilities**:
1. Entity resolution detects ambiguity ‚úÖ
2. Raise AmbiguousEntityError ‚úÖ
3. API returns 422 with candidate list ‚úÖ
4. Disambiguation flow (user selects) ‚ùå
5. Alias learning from selection ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService raises `AmbiguousEntityError` when multiple fuzzy matches
- ‚úÖ API chat.py (line 227-240) catches and returns 422 with candidates
- ‚ùå No /disambiguate endpoint to accept user selection
- ‚úÖ EntityAlias table can store user-specific aliases

**Missing**:
```python
# New endpoint needed
@router.post("/api/v1/disambiguate")
async def resolve_ambiguous_entity(
    mention: str,
    selected_entity_id: str,
    user_id: str
) -> EntityResponse:
    # Create user-specific alias
    # Return resolved entity
```

**Verdict**: **PARTIAL** - Core detection works, but need disambiguation flow API (1-2 hours work).

---

### üü° Scenario 6: SLA Breach Detection

**ProjectDescription**: "Detect SLA breaches by querying tasks table + calculating age. Tag high-risk items."

**Required Capabilities**:
1. Entity resolution for customer ‚úÖ
2. Domain DB query for `tasks` ‚ùå
3. Age calculation (today - created_date) ‚úÖ (can do in Python)
4. Risk tagging logic ‚ùå
5. LLM reply with breach warnings ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService works
- ‚ùå DomainAugmentationService doesn't query `domain.tasks` yet
- ‚úÖ Age calculation is trivial (Python datetime)
- ‚ùå No risk tagging in domain_facts metadata
- ‚úÖ LLMReplyGenerator can synthesize warnings

**Missing**:
```python
# In DomainAugmentationService
elif entity_type == "task":
    return EntityInfo(
        table="domain.tasks",
        id_field="task_id",
        name_field="title",
        join_from="customers",
        related_tables=[]
    )

# Add age calculation and risk tagging in _augment_entity_facts()
age_days = (datetime.now() - task_created_at).days
if age_days > 7:  # SLA breach threshold
    metadata["risk_level"] = "high"
    metadata["days_overdue"] = age_days - 7
```

**Verdict**: **PARTIAL** - Need task queries + risk tagging logic (2-3 hours work).

---

### üü° Scenario 7: Conflicting Memories Consolidation

**ProjectDescription**: "Memory says 'NET30', later user corrects to 'NET15'. System detects conflict, resolves with trust_recent."

**Required Capabilities**:
1. Conflict detection (memory vs memory) ‚úÖ
2. Consolidation rules: trust_recent, trust_reinforced ‚ùå
3. Supersession mechanism (mark old memory as superseded) ‚úÖ
4. MemoryConflict logging ‚úÖ
5. LLM reply explaining resolution ‚úÖ

**Current Implementation**:
- ‚úÖ ConflictDetectionService detects semantic memory conflicts
- ‚úÖ MemoryConflict table logs conflicts with conflict_type, resolution_strategy
- ‚úÖ SemanticMemory.superseded_by_memory_id exists
- ‚ùå Resolution strategy application not implemented
- ‚úÖ LLMReplyGenerator can explain

**Missing**:
```python
# In ConflictDetectionService or SemanticExtractionService
async def resolve_conflict(
    conflict: MemoryConflict,
    strategy: str  # "trust_recent" | "trust_reinforced" | "ask_user"
) -> SemanticMemory:
    if strategy == "trust_recent":
        # Mark older memory as superseded
        older_mem.status = "superseded"
        older_mem.superseded_by_memory_id = newer_mem.memory_id
        return newer_mem
    elif strategy == "trust_reinforced":
        # Compare reinforcement_count
        if mem1.reinforcement_count > mem2.reinforcement_count:
            return mem1
        # ...
```

**Verdict**: **PARTIAL** - Conflict detection exists, need resolution strategy implementation (3-4 hours work).

---

### üü° Scenario 8: Multilingual Alias Handling

**ProjectDescription**: "User says 'Gai Media' (English) and 'Gai Â™í‰Ωì' (Chinese). System learns both as aliases."

**Required Capabilities**:
1. Multilingual NER (extract mentions in multiple languages) ‚ùå
2. Entity resolution (fuzzy match across languages) ‚úÖ (pg_trgm may work)
3. Alias learning ‚úÖ
4. Unicode support ‚úÖ

**Current Implementation**:
- ‚ùå SimpleMentionExtractor uses regex, may miss non-ASCII entities
- ‚úÖ EntityAlias table supports unicode (Text column)
- ‚úÖ pg_trgm similarity can handle unicode
- ‚úÖ LLM coreference (Stage 4) can handle multilingual

**Missing**:
```python
# Option 1: Upgrade SimpleMentionExtractor to handle unicode word boundaries
# Option 2: Use LLM-based mention extraction for multilingual support

# In EntityResolutionService
# pg_trgm should work for Chinese/Unicode:
# SELECT similarity('Gai Media', 'Gai Â™í‰Ωì')  -- May return ~0.4-0.5
```

**Verdict**: **PARTIAL** - Entity resolution may work, but mention extraction needs multilingual NER (4-5 hours work for proper implementation).

---

### üü° Scenario 10: Active Recall for Stale Facts

**ProjectDescription**: "Memory 'Gai prefers Friday' is 120 days old. Before using, system asks user 'Is this still true?'"

**Required Capabilities**:
1. Passive decay calculation ‚úÖ
2. Staleness threshold detection ‚úÖ
3. Validation prompting (inject question in reply) ‚ùå
4. Memory status transition (aging ‚Üí validated or invalidated) ‚úÖ
5. User confirmation processing ‚ùå

**Current Implementation**:
- ‚úÖ MemoryValidationService calculates effective_confidence with decay
- ‚úÖ SemanticMemory.last_validated_at tracks validation
- ‚úÖ SemanticMemory.status supports "aging" state
- ‚ùå No automatic validation prompt injection
- ‚ùå No /validate endpoint to process user confirmation

**Missing**:
```python
# In MultiSignalScorer or LLMReplyGenerator
async def check_stale_memories(memories: List[SemanticMemory]) -> List[str]:
    """Return validation questions for stale memories."""
    questions = []
    for mem in memories:
        days_old = (now() - mem.last_validated_at).days
        if days_old > 90 and mem.confidence < 0.6:
            questions.append(
                f"Quick check: Is '{mem.predicate}: {mem.object_value}' still accurate?"
            )
    return questions

# New endpoint
@router.post("/api/v1/validate")
async def validate_memory(memory_id: int, is_valid: bool):
    # If valid: Update last_validated_at, boost confidence
    # If invalid: Mark status="invalidated"
```

**Verdict**: **PARTIAL** - Decay calculation exists, need validation prompting + API (3-4 hours work).

---

### üü° Scenario 11: Cross-Object Reasoning

**ProjectDescription**: "User asks 'Can we invoice Gai Media?' System traverses: Customer ‚Üí Sales Orders ‚Üí Work Orders ‚Üí Invoices."

**Required Capabilities**:
1. Entity resolution for customer ‚úÖ
2. Multi-hop queries (join across 3+ tables) ‚ùå
3. Ontology traversal (follow relationship graph) ‚ùå
4. Business logic (can't invoice until work complete) ‚ùå
5. LLM reply with reasoning ‚úÖ

**Current Implementation**:
- ‚úÖ DomainOntology table exists with join_spec
- ‚úÖ DomainAugmentationService can query single tables
- ‚ùå No multi-hop query logic
- ‚ùå OntologyService exists but not integrated into augmentation pipeline
- ‚úÖ LLMReplyGenerator can synthesize reasoning

**Missing**:
```python
# In DomainAugmentationService
async def traverse_ontology(
    start_entity_id: str,
    start_entity_type: str,
    target_entity_types: List[str]  # e.g., ["work_order", "invoice"]
) -> List[DomainFact]:
    """Traverse relationship graph to fetch related entities."""
    # 1. Query DomainOntology for customer ‚Üí sales_order
    # 2. Query DomainOntology for sales_order ‚Üí work_order
    # 3. Query DomainOntology for work_order ‚Üí invoice
    # 4. Execute JOIN queries
    # 5. Return combined results

# Example query:
# SELECT i.*, wo.status as work_status
# FROM domain.customers c
# JOIN domain.sales_orders so ON so.customer_id = c.customer_id
# JOIN domain.work_orders wo ON wo.so_id = so.so_id
# LEFT JOIN domain.invoices i ON i.so_id = so.so_id
# WHERE c.customer_id = :customer_id
```

**Verdict**: **PARTIAL** - Single-table queries work, need multi-hop ontology traversal (5-6 hours work).

---

### üü° Scenario 12: Fuzzy Match + Alias Learning

**ProjectDescription**: "User says 'Kay Media' (typo). System fuzzy matches to 'Gai Media', automatically creates alias."

**Required Capabilities**:
1. Fuzzy matching (pg_trgm) ‚úÖ
2. Automatic alias creation from fuzzy match ‚ùå
3. EntityAlias storage ‚úÖ
4. Confidence tracking ‚úÖ

**Current Implementation**:
- ‚úÖ EntityResolutionService Stage 3 uses fuzzy matching (pg_trgm similarity)
- ‚úÖ Returns confidence score for fuzzy matches
- ‚ùå Doesn't automatically create EntityAlias from fuzzy matches
- ‚úÖ EntityAlias table ready

**Missing**:
```python
# In EntityResolutionService.resolve()
# After Stage 3 (fuzzy match) succeeds:
if fuzzy_result:
    # Automatically create alias for future exact matches
    await self.entity_repo.create_alias(
        canonical_entity_id=fuzzy_result.entity_id,
        alias_text=mention_text,
        alias_source="fuzzy",
        user_id=user_id,  # User-specific
        confidence=fuzzy_result.confidence
    )
```

**Verdict**: **PARTIAL** - Fuzzy matching works, just need auto-alias creation (1-2 hours work).

---

### üü° Scenario 13: PII Guardrail Memory

**ProjectDescription**: "User mentions SSN. System detects PII, redacts from storage, stores policy memory 'Do not store SSN'."

**Required Capabilities**:
1. PII detection (regex or LLM) ‚ùå (service exists, needs implementation)
2. Redaction before storage ‚ùå
3. Policy memory: `{predicate: "pii_policy", object_value: "never_store_ssn"}` ‚úÖ
4. Guardrail enforcement ‚ùå

**Current Implementation**:
- üü° PIIRedactionService exists in services but implementation incomplete
- ‚úÖ SemanticMemory supports predicate_type="policy"
- ‚ùå No PII detection in pipeline (not called from ProcessChatMessageUseCase)
- ‚ùå No redaction before ChatEvent storage

**Missing**:
```python
# In PIIRedactionService
async def detect_pii(text: str) -> List[PIIMatch]:
    """Detect PII entities: SSN, credit card, email, phone."""
    matches = []
    # SSN pattern
    ssn_pattern = r'\b\d{3}-\d{2}-\d{4}\b'
    for match in re.finditer(ssn_pattern, text):
        matches.append(PIIMatch(
            type="ssn",
            start=match.start(),
            end=match.end(),
            text=match.group()
        ))
    # ... more patterns ...
    return matches

async def redact(text: str, matches: List[PIIMatch]) -> str:
    """Replace PII with [REDACTED-{type}]."""
    # Replace in reverse order to preserve indices
    # ...

# In ProcessChatMessageUseCase.execute()
# Before storing message:
pii_matches = await self.pii_service.detect_pii(input_dto.content)
if pii_matches:
    redacted_content = await self.pii_service.redact(input_dto.content, pii_matches)
    # Store policy memory: "User mentioned PII, redaction applied"
```

**Verdict**: **PARTIAL** - Service exists, needs full implementation + pipeline integration (4-5 hours work).

---

### üü° Scenario 14: Session Window Consolidation

**ProjectDescription**: "After 3 sessions discussing Gai Media, system consolidates 15 episodic memories into 1 summary."

**Required Capabilities**:
1. ConsolidationTriggerService (detect ‚â•10 episodes, ‚â•3 sessions) ‚úÖ
2. ConsolidationService (LLM summarization) ‚úÖ
3. MemorySummary creation ‚úÖ
4. Source memory deprioritization ‚úÖ
5. /consolidate endpoint ‚ùå

**Current Implementation**:
- ‚úÖ ConsolidationTriggerService checks episode count + session count
- ‚úÖ ConsolidationService uses LLM to generate summary
- ‚úÖ MemorySummary table with scope_type, key_facts, source_data
- ‚úÖ Can mark EpisodicMemory with lower importance
- ‚ùå No API endpoint to trigger consolidation

**Missing**:
```python
# In src/api/routes/consolidation.py (file exists, needs implementation)
@router.post("/api/v1/consolidate")
async def trigger_consolidation(
    scope_type: str,  # "entity" | "topic" | "session_window"
    scope_identifier: str,  # e.g., customer_id or topic name
    user_id: str
) -> ConsolidationResponse:
    # Check trigger conditions
    should_consolidate = await consolidation_trigger.should_consolidate(...)
    if not should_consolidate:
        return {"message": "Consolidation threshold not met"}

    # Run consolidation
    summary = await consolidation_service.consolidate(...)
    return {"summary_id": summary.summary_id, "summary_text": summary.summary_text}
```

**Verdict**: **PARTIAL** - Services ready, just need API endpoint exposure (1-2 hours work).

---

### üü° Scenario 15: Audit Trail / Explainability

**ProjectDescription**: "User asks 'Why did you say Kai Media prefers Fridays?' System returns memory IDs, similarity scores, source chat events."

**Required Capabilities**:
1. Provenance tracking (source_memory_id, extracted_from_event_id) ‚úÖ
2. Memory retrieval with scores ‚úÖ
3. /explain endpoint ‚ùå
4. Citation linking ‚úÖ

**Current Implementation**:
- ‚úÖ SemanticMemory.extracted_from_event_id links to ChatEvent
- ‚úÖ SemanticMemory.source_memory_id tracks consolidation provenance
- ‚úÖ ProcessChatMessageOutput includes retrieved_memories with relevance_score
- ‚ùå No /explain endpoint to query specific memory provenance
- ‚úÖ All data for explainability exists in database

**Missing**:
```python
# In src/api/routes/retrieval.py (or new explainability.py)
@router.post("/api/v1/explain")
async def explain_memory(
    memory_id: int,
    user_id: str
) -> ExplainResponse:
    """Return provenance trail for a specific memory."""
    # 1. Fetch SemanticMemory
    # 2. Fetch source EpisodicMemory (if exists)
    # 3. Fetch source ChatEvent (extracted_from_event_id)
    # 4. Fetch consolidation source (if from MemorySummary)
    # 5. Return full provenance chain

    return {
        "memory_id": memory_id,
        "predicate": memory.predicate,
        "confidence": memory.confidence,
        "source_event": {
            "event_id": event.event_id,
            "content": event.content,
            "created_at": event.created_at
        },
        "reinforcements": [...],  # Other events that reinforced this
        "consolidation_source": {...}  # If from summary
    }
```

**Verdict**: **PARTIAL** - All data tracked, just need /explain API endpoint (2-3 hours work).

---

### ‚ùå Scenario 16: Reminder Creation from Conversational Intent

**ProjectDescription**: "User: 'If invoice is open 3 days before due, remind me.' System stores procedural memory, checks trigger on future queries."

**Required Capabilities**:
1. Procedural memory extraction (LLM parse policy statement) ‚ùå
2. ProceduralMemory storage ‚úÖ
3. Trigger pattern matching ‚ùå
4. Proactive notice surfacing ‚ùå

**Current Implementation**:
- ‚úÖ ProceduralMemory table exists with trigger_pattern, trigger_features, action_heuristic
- ‚úÖ ProceduralMemoryService exists
- ‚ùå No LLM-based extraction from conversational policy statements
- ‚ùå Not integrated into ProcessChatMessageUseCase pipeline
- ‚ùå No trigger checking logic in retrieval/augmentation

**Missing**:
```python
# 1. Extraction logic (in SemanticExtractionService or new ProceduralExtractionService)
async def extract_procedural_memory(content: str) -> Optional[ProceduralMemoryDTO]:
    """Use LLM to detect policy/trigger statements."""
    # LLM prompt:
    # "Does this statement express a policy or trigger-action rule?
    #  If yes, extract:
    #  - trigger_pattern: When does this apply?
    #  - action_heuristic: What should happen?
    #  - trigger_features: {intent, entity_types, topics}"

    # Example output:
    # trigger_pattern: "invoice due date approaching"
    # trigger_features: {intent: "payment_reminder", entity_types: ["invoice"], topics: ["due_date"]}
    # action_heuristic: "If invoice.status='open' AND (due_date - today) <= 3 days, surface reminder"

# 2. Trigger checking (in DomainAugmentationService or new ProactiveNoticeService)
async def check_procedural_triggers(
    domain_facts: List[DomainFact],
    query_text: str
) -> List[ProactiveNotice]:
    """Check if any procedural memories match current context."""
    # 1. Retrieve ProceduralMemories via semantic similarity
    # 2. For each, evaluate trigger_features against query + domain_facts
    # 3. If match, execute action_heuristic (e.g., check invoice due dates)
    # 4. Return proactive notices

# 3. Integration into pipeline
# In ProcessChatMessageUseCase.execute()
# After domain augmentation:
proactive_notices = await self.check_triggers(domain_facts, input_dto.content)
# Include in LLMReplyGenerator context
```

**Verdict**: **MISSING CORE** - Table exists, but extraction + trigger logic completely missing (6-8 hours work).

---

### üü° Scenario 17: Error Handling When DB and Memory Disagree

**ProjectDescription**: "Memory says 'SO-1001 fulfilled', DB says 'in_fulfillment'. System prefers DB, logs conflict."

**Required Capabilities**:
1. Conflict detection (memory vs DB) ‚úÖ
2. Resolution: trust_db ‚úÖ
3. MemoryConflict logging ‚úÖ
4. Conflict exposure in API response ‚ùå

**Current Implementation**:
- ‚úÖ ConflictDetectionService.detect_memory_vs_db_conflicts() exists
- ‚úÖ MemoryConflict table logs with conflict_type="memory_vs_db"
- ‚úÖ Resolution_strategy="trust_db" stored
- ‚ùå Conflicts not exposed in ProcessChatMessageOutput or API response
- ‚úÖ LLMReplyGenerator could explain if conflicts were passed to it

**Missing**:
```python
# In ProcessChatMessageOutput DTO
@dataclass
class ProcessChatMessageOutput:
    # ... existing fields ...
    conflicts_detected: List[ConflictDTO] = field(default_factory=list)  # ADD THIS

# In ProcessChatMessageUseCase.execute()
# After semantic extraction:
conflicts = semantics_result.conflicts  # ConflictDetectionService should return these

# Pass to output:
return ProcessChatMessageOutput(
    # ...
    conflicts_detected=[
        ConflictDTO(
            conflict_type="memory_vs_db",
            memory_value=conflict.memory_value,
            db_value=conflict.db_value,
            resolution="trust_db"
        )
        for conflict in conflicts
    ]
)

# In API response (chat.py):
"conflicts_detected": [...]  # Add to simplified response
```

**Verdict**: **PARTIAL** - Detection works, just need to expose in API response (1-2 hours work).

---

### ‚ùå Scenario 18: Task Completion via Conversation

**ProjectDescription**: "User: 'Mark SLA investigation task as done and summarize.' System updates task, stores summary as semantic memory."

**Required Capabilities**:
1. Task queries (domain.tasks) ‚ùå
2. SQL patch suggestion / mocked update ‚ùå
3. Semantic memory storage for summary ‚úÖ
4. LLM reply acknowledging task completion ‚úÖ

**Current Implementation**:
- ‚ùå DomainAugmentationService doesn't query `domain.tasks`
- ‚ùå No task update logic (would need new use case or endpoint)
- ‚úÖ SemanticExtractionService can store summary as semantic memory
- ‚úÖ LLMReplyGenerator can acknowledge

**Missing**:
```python
# 1. Task queries in DomainAugmentationService
elif entity_type == "task":
    return EntityInfo(
        table="domain.tasks",
        id_field="task_id",
        name_field="title",
        join_from="customers",
        related_tables=[]
    )

# 2. New use case or endpoint for task updates
@router.post("/api/v1/tasks/{task_id}/complete")
async def complete_task(
    task_id: str,
    summary: str,
    user_id: str
) -> TaskCompletionResponse:
    # Option A: Return SQL patch suggestion
    sql = f"UPDATE domain.tasks SET status='done', completed_at=NOW() WHERE task_id='{task_id}'"

    # Option B: Actually update (requires write access to domain DB)
    await domain_repo.update_task_status(task_id, "done")

    # Store summary as semantic memory
    semantic_memory = await semantic_extraction_service.create_memory(
        subject_entity_id=f"task_{task_id}",
        predicate="completion_summary",
        object_value={"summary": summary, "completed_at": now()},
        confidence=0.9
    )

    return {"status": "completed", "sql_patch": sql, "memory_id": semantic_memory.memory_id}
```

**Verdict**: **MISSING CORE** - Need task queries + task update flow (4-5 hours work).

---

## Summary by Capability Gap

### Gap 1: Domain Table Queries (MEDIUM PRIORITY)

**Missing Tables in DomainAugmentationService**:
- `domain.work_orders` (Scenario 2)
- `domain.tasks` (Scenarios 6, 18)

**Effort**: 2-3 hours (add EntityInfo mappings)

**Impact**: Unblocks 3 scenarios (#2, #6, #18)

---

### Gap 2: Procedural Memory Extraction (HIGH PRIORITY)

**Missing**:
- LLM-based policy statement extraction
- Trigger pattern recognition
- Proactive notice checking
- Integration into chat pipeline

**Effort**: 6-8 hours (complex LLM integration)

**Impact**: Unblocks 1 scenario (#16), enables proactive intelligence

---

### Gap 3: API Endpoints (LOW PRIORITY - QUICK WINS)

**Missing Endpoints**:
- `/api/v1/consolidate` (Scenario 14)
- `/api/v1/explain` (Scenario 15)
- `/api/v1/disambiguate` (Scenario 3)
- `/api/v1/validate` (Scenario 10)

**Effort**: 1-2 hours each (4-8 hours total)

**Impact**: Unblocks 4 scenarios (#3, #10, #14, #15)

---

### Gap 4: Advanced Features (LOW-MEDIUM PRIORITY)

**Missing**:
- Multi-hop ontology traversal (Scenario 11) - 5-6 hours
- Multilingual NER (Scenario 8) - 4-5 hours
- PII detection pipeline integration (Scenario 13) - 4-5 hours
- Active validation prompting (Scenario 10) - 3-4 hours
- Consolidation resolution strategies (Scenario 7) - 3-4 hours

**Effort**: 19-24 hours total

**Impact**: Unblocks 5 scenarios (#7, #8, #10, #11, #13)

---

### Gap 5: Minor Enhancements (LOW PRIORITY - QUICK WINS)

**Missing**:
- Auto-alias creation from fuzzy matches (Scenario 12) - 1-2 hours
- Conflict exposure in API (Scenario 17) - 1-2 hours
- Task completion flow (Scenario 18) - 4-5 hours

**Effort**: 6-9 hours total

**Impact**: Unblocks 3 scenarios (#12, #17, #18)

---

## Recommended Implementation Order

### Phase 1: Quick Wins (8-12 hours) ‚Üí 7 more scenarios passing

1. **Add domain table queries** (2-3 hours)
   - work_orders, tasks
   - Unblocks: #2, #6, #18 (partial)

2. **API endpoints** (4-8 hours)
   - /consolidate, /explain, /disambiguate
   - Unblocks: #3, #14, #15

3. **Auto-alias + conflict exposure** (2-3 hours)
   - Unblocks: #12, #17

**Result**: 11/18 scenarios passing (61%)

---

### Phase 2: Core Features (15-20 hours) ‚Üí 4 more scenarios passing

4. **Consolidation resolution strategies** (3-4 hours)
   - trust_recent, trust_reinforced
   - Unblocks: #7

5. **Active validation prompting** (3-4 hours)
   - Stale memory validation flow
   - Unblocks: #10

6. **Multi-hop ontology traversal** (5-6 hours)
   - Cross-object reasoning
   - Unblocks: #11

7. **Task completion flow** (4-5 hours)
   - SQL patch suggestion
   - Fully unblocks: #18

**Result**: 15/18 scenarios passing (83%)

---

### Phase 3: Advanced Features (16-21 hours) ‚Üí 3 more scenarios passing

8. **Procedural memory extraction** (6-8 hours)
   - LLM policy extraction + trigger checking
   - Unblocks: #16

9. **PII detection pipeline** (4-5 hours)
   - Full PII redaction integration
   - Unblocks: #13

10. **Multilingual NER** (4-5 hours)
    - Unicode mention extraction
    - Unblocks: #8

**Result**: 18/18 scenarios passing (100%)

---

## Final Verdict

**Your codebase is VERY WELL POSITIONED** to handle most scenarios:

### Strengths ‚úÖ
- Complete 6-layer memory architecture
- Robust entity resolution (5-stage hybrid)
- Semantic extraction with conflict detection
- Domain augmentation with database integration
- Memory scoring with multi-signal retrieval
- LLM reply generation with full context
- Comprehensive service layer

### What You Have That Most Don't ‚úÖ
- ProceduralMemory table (many systems skip this)
- MemoryConflict explicit tracking (rare)
- DomainOntology relationship semantics (very rare)
- Consolidation services (often missing)
- PIIRedactionService skeleton (forward-thinking)

### Quick Wins to Focus On üéØ
1. Add work_orders/tasks to domain queries (3 hours) ‚Üí +3 scenarios
2. Expose API endpoints (6 hours) ‚Üí +3 scenarios
3. Auto-alias + conflict exposure (3 hours) ‚Üí +2 scenarios

**12 hours of work ‚Üí 11/18 scenarios (61% ‚Üí 61%)**

### Major Features for 100% Coverage üèÜ
- Procedural memory extraction (8 hours) ‚Üí Critical for proactive intelligence
- Multi-hop queries (6 hours) ‚Üí Essential for complex reasoning
- Active validation (4 hours) ‚Üí Key for epistemic humility

**Overall, you're ~35-45 hours from 100% scenario coverage**, with a very solid foundation that handles the hardest parts (memory architecture, entity resolution, semantic extraction).

Most systems would need 200+ hours to reach this point. Your architecture is excellent.
